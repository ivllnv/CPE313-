{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "annual-sandwich",
      "metadata": {
        "id": "annual-sandwich"
      },
      "source": [
        "# Activity 2.2 - Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "great-fireplace",
      "metadata": {
        "id": "great-fireplace"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to introduce how to apply transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "subjective-elimination",
      "metadata": {
        "id": "subjective-elimination"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural network\n",
        "* Demonstrate how to apply transfer learning in neural network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "simplified-azerbaijan",
      "metadata": {
        "id": "simplified-azerbaijan"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "* CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ordinary-crime",
      "metadata": {
        "id": "ordinary-crime"
      },
      "source": [
        "#### Procedures\n",
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comic-joining",
      "metadata": {
        "id": "comic-joining"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "moral-chair",
      "metadata": {
        "id": "moral-chair"
      },
      "source": [
        "Set the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sticky-metallic",
      "metadata": {
        "id": "sticky-metallic"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now\n",
        "batch_size = 128\n",
        "num_classes = 5\n",
        "epochs = 5\n",
        "img_rows, img_cols = 28, 28\n",
        "filters = 32\n",
        "pool_size = 2\n",
        "kernel_size = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "resident-activity",
      "metadata": {
        "id": "resident-activity"
      },
      "source": [
        "Set how the input data is loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "measured-queens",
      "metadata": {
        "id": "measured-queens"
      },
      "outputs": [],
      "source": [
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jewish-russell",
      "metadata": {
        "id": "jewish-russell"
      },
      "source": [
        "* Write a function to include all the training steps.\n",
        "* Use the model, training set, test set and number of classes as function parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "julian-batch",
      "metadata": {
        "id": "julian-batch"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "monetary-final",
      "metadata": {
        "id": "monetary-final"
      },
      "source": [
        "Shuffle and split the data between train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hollywood-amendment",
      "metadata": {
        "id": "hollywood-amendment"
      },
      "outputs": [],
      "source": [
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "committed-bench",
      "metadata": {
        "id": "committed-bench"
      },
      "source": [
        "Create two datasets\n",
        "* one with digits below 5\n",
        "* one with 5 and above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lesser-bradley",
      "metadata": {
        "id": "lesser-bradley"
      },
      "outputs": [],
      "source": [
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "talented-scheme",
      "metadata": {
        "id": "talented-scheme"
      },
      "source": [
        "* Define the feature layers that will used for transfer learning\n",
        "* Freeze these layers during fine-tuning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranging-neutral",
      "metadata": {
        "id": "ranging-neutral"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bulgarian-accuracy",
      "metadata": {
        "id": "bulgarian-accuracy"
      },
      "source": [
        "Define the classification layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "religious-timer",
      "metadata": {
        "id": "religious-timer"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yellow-puzzle",
      "metadata": {
        "id": "yellow-puzzle"
      },
      "source": [
        "Create a model by combining the feature layers and classification layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "governmental-portable",
      "metadata": {
        "id": "governmental-portable"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential(feature_layers + classification_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noticed-dairy",
      "metadata": {
        "id": "noticed-dairy"
      },
      "source": [
        "Check the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-syria",
      "metadata": {
        "id": "correct-syria",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249b547f-bdff-43bd-98b5-5f1525aa9d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600165 (2.29 MB)\n",
            "Trainable params: 600165 (2.29 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "productive-regular",
      "metadata": {
        "id": "productive-regular"
      },
      "source": [
        " Train the  model on the digits 5,6,7,8,9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-ticket",
      "metadata": {
        "id": "distinct-ticket",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b56c5061-3296-460b-b556-66c1a7114830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 47s 199ms/step - loss: 1.6040 - accuracy: 0.2148 - val_loss: 1.5772 - val_accuracy: 0.3065\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 43s 188ms/step - loss: 1.5739 - accuracy: 0.2793 - val_loss: 1.5428 - val_accuracy: 0.4483\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 43s 187ms/step - loss: 1.5409 - accuracy: 0.3539 - val_loss: 1.5058 - val_accuracy: 0.5801\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 44s 193ms/step - loss: 1.5043 - accuracy: 0.4281 - val_loss: 1.4644 - val_accuracy: 0.6945\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 45s 194ms/step - loss: 1.4664 - accuracy: 0.4897 - val_loss: 1.4177 - val_accuracy: 0.7332\n",
            "Training time: 0:04:23.099686\n",
            "Test score: 1.4176816940307617\n",
            "Test accuracy: 0.7331824898719788\n"
          ]
        }
      ],
      "source": [
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "racial-emission",
      "metadata": {
        "id": "racial-emission"
      },
      "source": [
        "Freeze only the feature layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "violent-territory",
      "metadata": {
        "id": "violent-territory"
      },
      "outputs": [],
      "source": [
        "\n",
        "for l in feature_layers:\n",
        "    l.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "continuous-injection",
      "metadata": {
        "id": "continuous-injection"
      },
      "source": [
        "Check again the summary and observe the parameters from the previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sunset-manhattan",
      "metadata": {
        "id": "sunset-manhattan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e7b844b-4b09-4023-cdd8-1fec5229d120"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600165 (2.29 MB)\n",
            "Trainable params: 590597 (2.25 MB)\n",
            "Non-trainable params: 9568 (37.38 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "modern-carnival",
      "metadata": {
        "id": "modern-carnival"
      },
      "source": [
        "Train again the model using the 0 to 4 digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "comprehensive-nurse",
      "metadata": {
        "id": "comprehensive-nurse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8323c26f-9bbf-48c8-a146-8cc28025b673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 17s 69ms/step - loss: 1.5673 - accuracy: 0.2991 - val_loss: 1.5229 - val_accuracy: 0.4917\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.5143 - accuracy: 0.3771 - val_loss: 1.4676 - val_accuracy: 0.5655\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.4643 - accuracy: 0.4508 - val_loss: 1.4137 - val_accuracy: 0.6299\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 16s 68ms/step - loss: 1.4156 - accuracy: 0.5198 - val_loss: 1.3596 - val_accuracy: 0.7180\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 16s 66ms/step - loss: 1.3635 - accuracy: 0.5861 - val_loss: 1.3065 - val_accuracy: 0.7852\n",
            "Training time: 0:01:19.823630\n",
            "Test score: 1.306450366973877\n",
            "Test accuracy: 0.7851722240447998\n"
          ]
        }
      ],
      "source": [
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training and evaluation of this neural network model is divided in two phases: first, with only a subset of layers (5-9) trained while freezing earlier layers, and second, with the entire model trained. The second phase, where the entire model was trained, showed better performance in terms of accuracy on both training and test datasets compared to the first phase. Additionally, the training time for the second phase was shorter. This means that training the entire model without freezing any layers leads to better performance, likely due to the increased learning capacity from training all layers."
      ],
      "metadata": {
        "id": "2XCZhjYtoCSl"
      },
      "id": "2XCZhjYtoCSl"
    },
    {
      "cell_type": "markdown",
      "id": "numerical-integer",
      "metadata": {
        "id": "numerical-integer"
      },
      "source": [
        "#### Supplementary Activity\n",
        "Now write code to reverse this training process. That is, you will train on the digits 0-4, and then finetune only the last layers on the digits 5-9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "registered-venice",
      "metadata": {
        "id": "registered-venice"
      },
      "outputs": [],
      "source": [
        "model_sup = Sequential(feature_layers + classification_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first train the model on digits 0-4 (x_train_lt5, y_train_lt5)."
      ],
      "metadata": {
        "id": "H2euimF2Zh-8"
      },
      "id": "H2euimF2Zh-8"
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model_sup,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igJtexggFcU0",
        "outputId": "5d3daf10-23ff-48c4-d4ee-3beb16b7abf7"
      },
      "id": "igJtexggFcU0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "240/240 [==============================] - 16s 65ms/step - loss: 1.1046 - accuracy: 0.7473 - val_loss: 1.0296 - val_accuracy: 0.8449\n",
            "Epoch 2/5\n",
            "240/240 [==============================] - 17s 70ms/step - loss: 1.0608 - accuracy: 0.7741 - val_loss: 0.9843 - val_accuracy: 0.8615\n",
            "Epoch 3/5\n",
            "240/240 [==============================] - 15s 63ms/step - loss: 1.0185 - accuracy: 0.7931 - val_loss: 0.9423 - val_accuracy: 0.8745\n",
            "Epoch 4/5\n",
            "240/240 [==============================] - 16s 68ms/step - loss: 0.9807 - accuracy: 0.8093 - val_loss: 0.9032 - val_accuracy: 0.8801\n",
            "Epoch 5/5\n",
            "240/240 [==============================] - 17s 72ms/step - loss: 0.9463 - accuracy: 0.8206 - val_loss: 0.8666 - val_accuracy: 0.8866\n",
            "Training time: 0:01:22.918334\n",
            "Test score: 0.8666096925735474\n",
            "Test accuracy: 0.8865538239479065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for l in feature_layers:\n",
        "    l.trainable = False"
      ],
      "metadata": {
        "id": "TxiWQ80HFuR6"
      },
      "id": "TxiWQ80HFuR6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting trainable to False for the layers in feature_layers effectively freezes these layers during training. This helps keep the features they've learned intact."
      ],
      "metadata": {
        "id": "zoCxBnp0Z1j5"
      },
      "id": "zoCxBnp0Z1j5"
    },
    {
      "cell_type": "code",
      "source": [
        "model_sup.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ZETKZ3Fv_8",
        "outputId": "3f99bbea-78d3-4562-fe45-864b975a09cb"
      },
      "id": "Q_ZETKZ3Fv_8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 26, 26, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 12, 12, 32)        0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600165 (2.29 MB)\n",
            "Trainable params: 590597 (2.25 MB)\n",
            "Non-trainable params: 9568 (37.38 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now training the model (model_sup) on the subset of the MNIST dataset containing images of digits 5-9."
      ],
      "metadata": {
        "id": "FNrYjvrravR1"
      },
      "id": "FNrYjvrravR1"
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model_sup,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA9q5zIAe6S0",
        "outputId": "d6045e08-259b-47d1-ac90-532bcdaeea19"
      },
      "id": "RA9q5zIAe6S0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "230/230 [==============================] - 15s 64ms/step - loss: 1.2472 - accuracy: 0.5507 - val_loss: 1.1803 - val_accuracy: 0.6309\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 16s 69ms/step - loss: 1.2060 - accuracy: 0.5884 - val_loss: 1.1373 - val_accuracy: 0.6680\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 16s 70ms/step - loss: 1.1693 - accuracy: 0.6167 - val_loss: 1.0985 - val_accuracy: 0.7019\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 15s 64ms/step - loss: 1.1343 - accuracy: 0.6426 - val_loss: 1.0627 - val_accuracy: 0.7299\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 16s 70ms/step - loss: 1.0999 - accuracy: 0.6667 - val_loss: 1.0288 - val_accuracy: 0.7494\n",
            "Training time: 0:01:18.572260\n",
            "Test score: 1.0288006067276\n",
            "Test accuracy: 0.7494342923164368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the subset 0-4:\n",
        "* It achieved higher accuracy on both the training and test datasets.\n",
        "* It also has longer training time compared to the subset 5-9\n",
        "* Test accuracy reached 0.8865\n",
        "\n",
        "\n",
        "As for the subset 5-9:\n",
        "* It has lower accuracy compared to subset 0-4 on both training and test datasets.\n",
        "* It has shorter training time\n",
        "* The test accuracy reached 0.7494"
      ],
      "metadata": {
        "id": "oK-nsPw5og7Q"
      },
      "id": "oK-nsPw5og7Q"
    },
    {
      "cell_type": "markdown",
      "id": "cardiovascular-sapphire",
      "metadata": {
        "id": "cardiovascular-sapphire"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conditional-prerequisite",
      "metadata": {
        "id": "conditional-prerequisite"
      },
      "source": [
        "\n",
        "In this activity, we used Keras to create Convolutional Neural Networks or CNNs models, aimed at classifying handwritten digits from the MNIST dataset. We divided the dataset into two groups, one for numbers less than 5 and another for numbers 5 and above. For each group, we trained a separate model to learn from the data. During training, we also froze some layers in the models, which means we stopped them from learning further. This was done to ensure that the early layers, responsible for recognizing basic features, retained their knowledge. After training, we evaluated the models' accuracy on new, unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sacred-silence",
      "metadata": {
        "id": "sacred-silence"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}